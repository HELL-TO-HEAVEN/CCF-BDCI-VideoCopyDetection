{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, codecs\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.preprocessing import normalize as sknormalize\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "PATH = '/home/wx/work/video_copy_detection/'\n",
    "TRAIN_PATH = PATH + 'train/'\n",
    "TEST_PATH = PATH + 'test/'\n",
    "TRAIN_QUERY_PATH = TRAIN_PATH + 'query/'\n",
    "REFER_PATH = TRAIN_PATH + 'refer/'\n",
    "TRAIN_QUERY_FRAME_PATH = TRAIN_PATH + 'query_uniformframe/'\n",
    "REFER_FRAME_PATH = TRAIN_PATH + 'refer_uniformframe/'\n",
    "TEST_QUERY_PATH = TEST_PATH + 'query2/'\n",
    "TEST_QUERY_FRAME_PATH = TEST_PATH + 'query2_uniformframe/'\n",
    "CODE_DIR = PATH + 'code/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QRDataset(Dataset):\n",
    "    def __init__(self, img_path, transform = None):\n",
    "        self.img_path = img_path\n",
    "\n",
    "        self.img_label = np.zeros(len(img_path))\n",
    "    \n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path[index])\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, self.img_path[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "class Img2Vec():\n",
    "\n",
    "    def __init__(self, model='resnet-18', layer='default', layer_output_size=512):\n",
    "        \"\"\" Img2Vec\n",
    "        :param model: String name of requested model\n",
    "        :param layer: String or Int depending on model.\n",
    "        :param layer_output_size: Int depicting the output size of the requested layer\n",
    "        \"\"\"\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.layer_output_size = layer_output_size\n",
    "        self.model_name = model\n",
    "        \n",
    "        self.model, self.extraction_layer = self._get_model_and_layer(model, layer)\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        self.transformer = transforms.Compose([\n",
    "            transforms.Resize((224, 224)), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "    def get_vec(self, path):\n",
    "        \"\"\" Get vector embedding from PIL image\n",
    "        :param path: Path of image dataset\n",
    "        :returns: Numpy ndarray\n",
    "        \"\"\"\n",
    "        if not isinstance(path, list):\n",
    "            path = [path]\n",
    "\n",
    "        data_loader = torch.utils.data.DataLoader(QRDataset(path, self.transformer), batch_size = 40, \n",
    "                                                  shuffle = False, num_workers = 16)\n",
    "\n",
    "        my_embedding = []\n",
    "\n",
    "        # hook function\n",
    "        def append_data(module, input, output):\n",
    "            my_embedding.append(output.clone().detach().cpu().numpy())\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for batch_data in tqdm(data_loader):\n",
    "                batch_x, batch_y = batch_data\n",
    "                if torch.cuda.is_available():\n",
    "                    batch_x = Variable(batch_x, requires_grad = False).cuda()\n",
    "                else:\n",
    "                    batch_x = Variable(batch_x, requires_grad = False)\n",
    "\n",
    "                h = self.extraction_layer.register_forward_hook(append_data)\n",
    "                h_x = self.model(batch_x)\n",
    "                h.remove()\n",
    "                del h_x\n",
    "\n",
    "        my_embedding = np.vstack(my_embedding)\n",
    "        if self.model_name == 'alexnet':\n",
    "            return my_embedding[:, :]\n",
    "        else:\n",
    "            return my_embedding[:, :, 0, 0]\n",
    "\n",
    "    def _get_model_and_layer(self, model_name, layer):\n",
    "        \"\"\" Internal method for getting layer from model\n",
    "        :param model_name: model name such as 'resnet-18'\n",
    "        :param layer: layer as a string for resnet-18 or int for alexnet\n",
    "        :returns: pytorch model, selected layer\n",
    "        \"\"\"\n",
    "        if model_name == 'resnet-18':\n",
    "            model = models.resnet18(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model._modules.get('avgpool')\n",
    "                self.layer_output_size = 512\n",
    "            else:\n",
    "                layer = model._modules.get(layer)\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        elif model_name == 'alexnet':\n",
    "            model = models.alexnet(pretrained=True)\n",
    "            if layer == 'default':\n",
    "                layer = model.classifier[-2]\n",
    "                self.layer_output_size = 4096\n",
    "            else:\n",
    "                layer = model.classifier[-layer]\n",
    "\n",
    "            return model, layer\n",
    "\n",
    "        else:\n",
    "            raise KeyError('Model %s was not found' % model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 test_query 视频的帧，并按照视频和帧时间进行排序\n",
    "test_query_imgs_path = []\n",
    "for id in pd.read_csv(TEST_PATH + 'submit_example2.csv')['query_id']:\n",
    "    test_query_imgs_path += glob.glob(TEST_QUERY_FRAME_PATH + id + '/*.jpg')\n",
    "\n",
    "test_query_imgs_path.sort(key = lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 train_query 视频的帧，并按照视频和帧时间进行排序\n",
    "train_query_imgs_path = []\n",
    "for id in pd.read_csv(TRAIN_PATH + 'train.csv')['query_id']:\n",
    "    train_query_imgs_path += glob.glob(TRAIN_QUERY_FRAME_PATH + id + '/*.jpg')\n",
    "\n",
    "train_query_imgs_path.sort(key = lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 refer 视频的帧，并按照视频和帧时间进行排序\n",
    "\n",
    "refer_imgs_path = glob.glob(REFER_FRAME_PATH + '*/*.jpg')\n",
    "refer_imgs_path.sort(key = lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Img2Vec\n",
    "img2vec = Img2Vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1396/24966 [02:50<14:28, 27.12it/s]   "
     ]
    }
   ],
   "source": [
    "# 抽取 test_query 关键帧特征\n",
    "test_query_features = img2vec.get_vec(test_query_imgs_path[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽取 train_query 关键帧特征\n",
    "train_query_features = img2vec.get_vec(train_query_imgs_path[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽取 refer 关键帧特征\n",
    "refer_features = img2vec.get_vec(list(refer_imgs_path[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, copy = False):\n",
    "    \"\"\"\n",
    "    A helper function that wraps the function of the same name in sklearn.\n",
    "    This helper handles the case of a single column vector.\n",
    "    \"\"\"\n",
    "    if type(x) == np.ndarray and len(x.shape) == 1:\n",
    "        return np.squeeze(sknormalize(x.reshape(1, -1), copy = copy))\n",
    "        #return np.squeeze(x / np.sqrt((x ** 2).sum(-1))[..., np.newaxis])\n",
    "    else:\n",
    "        return sknormalize(x, copy = copy)\n",
    "        #return x / np.sqrt((x ** 2).sum(-1))[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA 降维\n",
    "'''\n",
    "pca = PCA(n_components=512)\n",
    "\n",
    "train_query_features = pca.fit_transform(train_query_features)\n",
    "test_query_features = pca.fit_transform(test_query_features)\n",
    "refer_features = pca.fit_transform(refer_features)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2正则化\n",
    "train_query_features = normalize(train_query_features)\n",
    "test_query_features = normalize(test_query_features)\n",
    "refer_features = normalize(refer_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存 test_query 帧特征\n",
    "\n",
    "with open(PATH + 'var/test_query_features_uni.pk', 'wb') as pk_file:\n",
    "    pickle.dump(test_query_features, pk_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存 train_query 帧特征\n",
    "\n",
    "with open(PATH + 'var/train_query_features_uni.pk', 'wb') as pk_file:\n",
    "    pickle.dump(train_query_features, pk_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存 refer 帧特征\n",
    "\n",
    "with open(PATH + 'var/refer_features_uni.pk', 'wb') as pk_file:\n",
    "    pickle.dump(refer_features, pk_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
