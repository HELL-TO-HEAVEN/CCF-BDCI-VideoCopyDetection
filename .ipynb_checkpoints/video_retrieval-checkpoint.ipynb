{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相似视频检索\n",
    "\n",
    "视频级相似匹配 -> 帧级匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import imagehash\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial.distance import cosine\n",
    "from networkx.algorithms.dag import dag_longest_path\n",
    "\n",
    "PATH = '/home/wx/work/video_copy_detection/'\n",
    "TRAIN_PATH = PATH + 'train/'\n",
    "TEST_PATH = PATH + 'test/'\n",
    "TRAIN_QUERY_PATH = TRAIN_PATH + 'query/'\n",
    "REFER_PATH = TRAIN_PATH + 'refer/'\n",
    "TRAIN_QUERY_FRAME_PATH = TRAIN_PATH + 'query_uniformframe/'\n",
    "REFER_FRAME_PATH = TRAIN_PATH + 'refer_uniformframe/'\n",
    "TEST_QUERY_PATH = TEST_PATH + 'query2/'\n",
    "TEST_QUERY_FRAME_PATH = TEST_PATH + 'query2_uniformframe/'\n",
    "CODE_DIR = PATH + 'code/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取特征文件\n",
    "with open(PATH + 'var/train_query_features_uni.pk', 'rb') as pk_file:\n",
    "    train_query_features = pickle.load(pk_file)\n",
    "\n",
    "with open(PATH + 'var/test_query_features_uni.pk', 'rb') as pk_file:\n",
    "    test_query_features = pickle.load(pk_file)\n",
    "\n",
    "with open(PATH + 'var/refer_features_uni.pk', 'rb') as pk_file:\n",
    "    refer_features = pickle.load(pk_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取特征文件\n",
    "with open(PATH + 'var/train_query_features_res50_uni.pk', 'rb') as pk_file:\n",
    "    train_query_features = pickle.load(pk_file)\n",
    "    \n",
    "with open(PATH + 'var/test_query_features_res50_uni.pk', 'rb') as pk_file:\n",
    "    test_query_features = pickle.load(pk_file)\n",
    "\n",
    "with open(PATH + 'var/refer_features_res50_uni.pk', 'rb') as pk_file:\n",
    "    refer_features = pickle.load(pk_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375702, 2048)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_query_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 train_query 视频的关键帧\n",
    "# 按照视频和关键帧时间进行排序\n",
    "# 预处理工具 dict\n",
    "train_query_imgs_path = []\n",
    "train_query_vids = []\n",
    "train_query_vid2idx = {}\n",
    "train_query_idx2vid = {}\n",
    "train_query_vid2baseaddr = {}\n",
    "train_query_fid2path = {}\n",
    "train_query_fid2vid = {}\n",
    "train_query_fid2time = {}\n",
    "\n",
    "for id in pd.read_csv(TRAIN_PATH + 'train.csv')['query_id']:\n",
    "    train_query_imgs_path += glob.glob(TRAIN_QUERY_FRAME_PATH + id + '/*.jpg')\n",
    "    train_query_vids += [id]\n",
    "\n",
    "train_query_imgs_path.sort(key = lambda x: x.lower())\n",
    "train_query_vids.sort(key = lambda x: x.lower())\n",
    "\n",
    "\n",
    "idx = 0\n",
    "for vid in train_query_vids:\n",
    "    train_query_vid2idx[vid] = idx\n",
    "    train_query_idx2vid[idx] = vid\n",
    "    idx += 1\n",
    "fid = 0\n",
    "pre_vid = \"\"\n",
    "cur_base = 0\n",
    "for idx, path in enumerate(train_query_imgs_path):\n",
    "    cur_vid = path.split('/')[-1][:-20]\n",
    "    train_query_fid2vid[fid] = cur_vid\n",
    "    train_query_fid2path[fid] = path\n",
    "    train_query_fid2time[fid] = float(path.split('/')[-1].split('_')[-1][:-4])\n",
    "    if pre_vid != cur_vid:\n",
    "        cur_base = idx\n",
    "        pre_vid = cur_vid\n",
    "    train_query_vid2baseaddr[cur_vid] = cur_base\n",
    "    fid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path.split('/')[-1][:-20]\n",
    "# float(path.split('/')[-1].split('_')[-1][:-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 test_query 视频的关键帧\n",
    "# 按照视频和关键帧时间进行排序\n",
    "# 预处理工具 dict\n",
    "test_query_imgs_path = []\n",
    "test_query_vids = []\n",
    "test_query_vid2idx = {}\n",
    "test_query_idx2vid = {}\n",
    "test_query_vid2baseaddr = {}\n",
    "test_query_fid2path = {}\n",
    "test_query_fid2vid = {}\n",
    "test_query_fid2time = {}\n",
    "\n",
    "for id in pd.read_csv(TEST_PATH + 'submit_example2.csv')['query_id']:\n",
    "    test_query_imgs_path += glob.glob(TEST_QUERY_FRAME_PATH + id + '/*.jpg')\n",
    "    test_query_vids += [id]\n",
    "\n",
    "test_query_imgs_path.sort(key = lambda x: x.lower())\n",
    "test_query_vids.sort(key = lambda x: x.lower())\n",
    "\n",
    "idx = 0\n",
    "for vid in test_query_vids:\n",
    "    test_query_vid2idx[vid] = idx\n",
    "    test_query_idx2vid[idx] = vid\n",
    "    idx += 1\n",
    "fid = 0\n",
    "pre_vid = \"\"\n",
    "cur_base = 0\n",
    "for idx, path in enumerate(test_query_imgs_path):\n",
    "    cur_vid = path.split('/')[-1][:-20]\n",
    "    test_query_fid2vid[fid] = cur_vid\n",
    "    test_query_fid2path[fid] = path\n",
    "    test_query_fid2time[fid] = float(path.split('/')[-1].split('_')[-1][:-4])\n",
    "    if pre_vid != cur_vid:\n",
    "        cur_base = idx\n",
    "        pre_vid = cur_vid\n",
    "    test_query_vid2baseaddr[cur_vid] = cur_base\n",
    "    fid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 refer_query 视频的关键帧\n",
    "# 按照视频和关键帧时间进行排序\n",
    "# 预处理工具 dict\n",
    "\n",
    "refer_imgs_path = glob.glob(REFER_FRAME_PATH + '*/*.jpg')\n",
    "refer_imgs_path.sort(key = lambda x: x.lower())\n",
    "\n",
    "refer_vids = []\n",
    "refer_vid2idx = {}\n",
    "refer_idx2vid = {}\n",
    "refer_vid2baseaddr = {}\n",
    "refer_fid2path = {}\n",
    "refer_fid2vid = {}\n",
    "refer_fid2time = {}\n",
    "\n",
    "for path in refer_imgs_path:\n",
    "    vid = path.split('/')[-2]\n",
    "    refer_vids += [vid]\n",
    "\n",
    "refer_vids = list(set(refer_vids))\n",
    "refer_vids.sort(key = lambda x: x.lower())\n",
    "\n",
    "idx = 0\n",
    "for vid in refer_vids:\n",
    "    refer_vid2idx[vid] = idx\n",
    "    refer_idx2vid[idx] = vid\n",
    "    idx += 1\n",
    "fid = 0\n",
    "pre_vid = \"\"\n",
    "cur_base = 0\n",
    "for idx, path in enumerate(refer_imgs_path):\n",
    "    cur_vid = path.split('/')[-1][:-20]\n",
    "    refer_fid2vid[fid] = cur_vid\n",
    "    refer_fid2path[fid] = path\n",
    "    refer_fid2time[fid] = float(path.split('/')[-1].split('_')[-1][:-4])\n",
    "    if pre_vid != cur_vid:\n",
    "        cur_base = idx\n",
    "        pre_vid = cur_vid\n",
    "    refer_vid2baseaddr[cur_vid] = cur_base\n",
    "    fid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids = np.concatenate((train_query_vids, test_query_vids, refer_vids), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征按视频归类\n",
    "if False:\n",
    "    vid2features = {}\n",
    "    for (path, cur_feat) in tqdm(zip(train_query_imgs_path, train_query_features)):\n",
    "        vid = path.split('/')[-2]\n",
    "        if(not vid in vid2features):\n",
    "            vid2features[vid] = [cur_feat]\n",
    "        else:\n",
    "            vid2features[vid] = np.concatenate((vid2features[vid], [cur_feat]), axis=0)\n",
    "\n",
    "    for (path, cur_feat) in tqdm(zip(test_query_imgs_path, test_query_features)):\n",
    "        vid = path.split('/')[-2]\n",
    "        if(not vid in vid2features):\n",
    "            vid2features[vid] = [cur_feat]\n",
    "        else:\n",
    "            vid2features[vid] = np.concatenate((vid2features[vid], [cur_feat]), axis=0)\n",
    "\n",
    "    for (path, cur_feat) in tqdm(zip(refer_imgs_path, refer_features)):\n",
    "        vid = path.split('/')[-2]\n",
    "        if(not vid in vid2features):\n",
    "            vid2features[vid] = [cur_feat]\n",
    "        else:\n",
    "            vid2features[vid] = np.concatenate((vid2features[vid], [cur_feat]), axis=0)\n",
    "            \n",
    "    # with open(PATH + 'var/vid2features_uni.pk', 'wb') as pk_file:\n",
    "    with open(PATH + 'var/vid2features_res50_uni.pk', 'wb') as pk_file:\n",
    "        pickle.dump(vid2features, pk_file)\n",
    "else:\n",
    "    with open(PATH + 'var/vid2features_uni.pk', 'rb') as pk_file:\n",
    "    # with open(PATH + 'var/vid2features_res50_uni.pk', 'rb') as pk_file:\n",
    "        vid2features = pickle.load(pk_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 512)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid2features[refer_vids[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarities(query_features, refer_features):\n",
    "    \"\"\"\n",
    "      用于计算两组特征(已经做过l2-norm)之间的相似度\n",
    "      Args:\n",
    "        query_features: shape: [N, D]\n",
    "        refer_features: shape: [M, D]\n",
    "      Returns:\n",
    "        sorted_sims: shape: [N, M]\n",
    "        unsorted_sims: shape: [N, M]\n",
    "    \"\"\"\n",
    "    sorted_sims = []\n",
    "    unsorted_sims = []\n",
    "    # 计算待查询视频和所有视频的距离\n",
    "    dist = np.nan_to_num(cdist(query_features, refer_features, metric='cosine'))\n",
    "    for i, v in enumerate(query_features):\n",
    "        # 归一化，将距离转化成相似度\n",
    "        # sim = np.round(1 - dist[i] / dist[i].max(), decimals=6)\n",
    "        sim = 1 - dist[i]\n",
    "        # 按照相似度的从大到小排列，输出index\n",
    "        unsorted_sims += [sim]\n",
    "        sorted_sims += [[(s, sim[s]) for s in sim.argsort()[::-1] if not np.isnan(sim[s])]]\n",
    "    return sorted_sims, unsorted_sims\n",
    "\n",
    "def compute_dists(query_features, refer_features):\n",
    "    \"\"\"\n",
    "      用于计算两组特征(已经做过l2-norm)之间的余弦距离\n",
    "      Args:\n",
    "        query_features: shape: [N, D]\n",
    "        refer_features: shape: [M, D]\n",
    "      Returns:\n",
    "        idxs: shape [N, M]\n",
    "        unsorted_dists: shape: [N, M]\n",
    "        sorted_dists: shape: [N, M]\n",
    "    \"\"\"\n",
    "    sims = np.dot(query_features, refer_features.T)\n",
    "    unsorted_dists = 1 - sims # sort 不好改降序\n",
    "    # unsorted_dist = np.nan_to_num(cdist(query_features, refer_features, metric='cosine'))\n",
    "    idxs = np.argsort(unsorted_dists)\n",
    "    rows = np.dot(np.arange(idxs.shape[0]).reshape((idxs.shape[0], 1)), np.ones((1, idxs.shape[1]))).astype(int)\n",
    "    sorted_dists = unsorted_dists[rows, idxs]\n",
    "    # sorted_dists = np.sort(unsorted_dists)\n",
    "    return idxs, unsorted_dists, sorted_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_alignment(query_features, refer_features, top_K=5, min_sim=0.80, max_step=10):\n",
    "    \"\"\"\n",
    "      用于计算两组特征(已经做过l2-norm)之间的帧匹配结果\n",
    "      Args:\n",
    "        query_features: shape: [N, D]\n",
    "        refer_features: shape: [M, D]\n",
    "        top_K: 取前K个refer_frame\n",
    "        min_sim: 要求query_frame与refer_frame的最小相似度\n",
    "        max_step: 有边相连的结点间的最大步长\n",
    "      Returns:\n",
    "        path_query: shape: [1, L]\n",
    "        path_refer: shape: [1, L]\n",
    "    \"\"\"\n",
    "    node_pair2id = {}\n",
    "    node_id2pair = {}\n",
    "    node_id2pair[0] = (-1, -1) # source\n",
    "    node_pair2id[(-1, -1)] = 0\n",
    "    node_num = 1\n",
    "\n",
    "    DG = nx.DiGraph()\n",
    "    DG.add_node(0)\n",
    "\n",
    "    idxs, unsorted_dists, sorted_dists = compute_dists(query_features, refer_features)\n",
    "\n",
    "    # add nodes\n",
    "    for qf_idx in range(query_features.shape[0]):\n",
    "        for k in range(top_K):\n",
    "            rf_idx = idxs[qf_idx][k]\n",
    "            sim = 1 - sorted_dists[qf_idx][k]\n",
    "            if sim < min_sim:\n",
    "                break\n",
    "            node_id2pair[node_num] = (qf_idx, rf_idx)\n",
    "            node_pair2id[(qf_idx, rf_idx)] = node_num\n",
    "            DG.add_node(node_num)\n",
    "            node_num += 1\n",
    "    \n",
    "    node_id2pair[node_num] = (query_features.shape[0], refer_features.shape[0]) # sink\n",
    "    node_pair2id[(query_features.shape[0], refer_features.shape[0])] = node_num\n",
    "    DG.add_node(node_num)\n",
    "    node_num += 1\n",
    "\n",
    "    # link nodes\n",
    "\n",
    "    for i in range(0, node_num - 1):\n",
    "        for j in range(i + 1, node_num - 1):\n",
    "            \n",
    "            pair_i = node_id2pair[i]\n",
    "            pair_j = node_id2pair[j]\n",
    "\n",
    "            if(pair_j[0] > pair_i[0] and pair_j[1] > pair_i[1] and\n",
    "               pair_j[0] - pair_i[0] <= max_step and pair_j[1] - pair_i[1] <= max_step):\n",
    "               qf_idx = pair_j[0]\n",
    "               rf_idx = pair_j[1]\n",
    "               DG.add_edge(i, j, weight=1 - unsorted_dists[qf_idx][rf_idx])\n",
    "\n",
    "    for i in range(0, node_num - 1):\n",
    "        j = node_num - 1\n",
    "\n",
    "        pair_i = node_id2pair[i]\n",
    "        pair_j = node_id2pair[j]\n",
    "\n",
    "        if(pair_j[0] > pair_i[0] and pair_j[1] > pair_i[1] and\n",
    "            pair_j[0] - pair_i[0] <= max_step and pair_j[1] - pair_i[1] <= max_step):\n",
    "            qf_idx = pair_j[0]\n",
    "            rf_idx = pair_j[1]\n",
    "            DG.add_edge(i, j, weight=0)\n",
    "\n",
    "    longest_path = dag_longest_path(DG)\n",
    "    if 0 in longest_path:\n",
    "        longest_path.remove(0) # remove source node\n",
    "    if node_num - 1 in longest_path:\n",
    "        longest_path.remove(node_num - 1) # remove sink node\n",
    "    path_query = [node_id2pair[node_id][0] for node_id in longest_path]\n",
    "    path_refer = [node_id2pair[node_id][1] for node_id in longest_path]\n",
    "\n",
    "    score = 0.0\n",
    "    for (qf_idx, rf_idx) in zip(path_query, path_refer):\n",
    "        score += 1 - unsorted_dists[qf_idx][rf_idx]\n",
    "\n",
    "    return path_query, path_refer, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totally cost 0.12647390365600586\n"
     ]
    }
   ],
   "source": [
    "time_start=time.time()\n",
    "qf = vid2features[train_query_vids[0]]\n",
    "rf = vid2features['1226686400']\n",
    "idxs, unsorted_dists, sorted_dists = compute_dists(qf, rf)\n",
    "time_end=time.time()\n",
    "print('totally cost',time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_time_range(ms): 57000|79000\n",
      "refer_time_range(ms): 3227000|3248000\n",
      "score: 7.64414119720459\n",
      "                                  query_id query_time_range(ms)    refer_id  \\\n",
      "1308  00530630-b8c8-11e9-930e-fa163ee49799         48290|116410  3184886800   \n",
      "\n",
      "     refer_time_range(ms)  \n",
      "1308      3217530|3285650  \n",
      "totally cost 0.2443249225616455\n"
     ]
    }
   ],
   "source": [
    "time_start=time.time()\n",
    "q_vid = '00530630-b8c8-11e9-930e-fa163ee49799'\n",
    "r_vid = '3184886800'\n",
    "query = vid2features[q_vid]\n",
    "refer = vid2features[r_vid]\n",
    "q_baseaddr = train_query_vid2baseaddr[q_vid]\n",
    "r_baseaddr = refer_vid2baseaddr[r_vid]\n",
    "path_query, path_refer, score = get_frame_alignment(query, refer) # local address\n",
    "\n",
    "time_query = [int(train_query_fid2time[q_baseaddr + qf_id] * 1000) for qf_id in path_query]\n",
    "time_refer = [int(refer_fid2time[r_baseaddr + rf_id] * 1000) for rf_id in path_refer]\n",
    "print(\"query_time_range(ms): {}|{}\".format(time_query[0], time_query[-1]))\n",
    "print(\"refer_time_range(ms): {}|{}\".format(time_refer[0], time_refer[-1]))\n",
    "print(\"score: {}\".format(score))\n",
    "#print(time_query)\n",
    "#print(time_refer)\n",
    "train_df = pd.read_csv(TRAIN_PATH + 'train.csv')\n",
    "print(train_df.loc[train_df['query_id'] == q_vid])\n",
    "time_end=time.time()\n",
    "print('totally cost',time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs, unsorted_dists, sorted_dists = compute_dists(vid2features[q_vid], vid2features[r_vid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(sorted_dists)):\\n    print(i)\\n    for j in range(5):\\n        print(idxs[i][j], 1-sorted_dists[i][j])\\n'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debug\n",
    "'''\n",
    "for i in range(len(sorted_dists)):\n",
    "    print(i)\n",
    "    for j in range(5):\n",
    "        print(idxs[i][j], 1-sorted_dists[i][j])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51.53578978776932, '1224903000', 92000, 175000, 486000, 575000)\n",
      "(42.96090793609619, '2274916400', 18000, 86000, 1284000, 1352000)\n",
      "(63.607283651828766, '1356122300', 0, 69000, 343000, 411000)\n",
      "(49.72458457946777, '1398481500', 0, 60000, 809000, 868000)\n",
      "(14.793390035629272, '2509505900', 82000, 111000, 1041000, 1070000)\n",
      "(3.442767322063446, '1500872700', 91000, 95000, 249000, 262000)\n",
      "(26.741500854492188, '2666192100', 28000, 64000, 4542000, 4593000)\n",
      "(70.90073662996292, '1176745900', 0, 79000, 1289000, 1368000)\n",
      "(49.04690796136856, '1659203000', 32000, 92000, 688000, 760000)\n",
      "(6.891523063182831, '1419310000', 9000, 32000, 3931000, 3954000)\n",
      "(24.807477474212646, '1332713900', 34000, 101000, 1995000, 2063000)\n",
      "(65.31166815757751, '2436435900', 7000, 86000, 1166000, 1245000)\n",
      "(33.87100577354431, '2342638000', 0, 50000, 6824000, 6875000)\n",
      "(20.107609510421753, '1887729500', 47000, 93000, 464000, 524000)\n",
      "(31.705184996128082, '1596058300', 0, 67000, 429000, 495000)\n",
      "(67.98666608333588, '1723849300', 52000, 120000, 2480000, 2548000)\n",
      "(48.84355956315994, '3043930400', 0, 49000, 1155000, 1216000)\n",
      "(30.62875211238861, '2845332600', 0, 50000, 3461000, 3509000)\n",
      "(6.086414098739624, '1534060400', 17000, 45000, 3671000, 3688000)\n",
      "(56.07742738723755, '3203967000', 0, 61000, 1272000, 1344000)\n",
      "(70.84944242238998, '2342638000', 0, 105000, 1508000, 1611000)\n",
      "(6.202283024787903, '1901179600', 50000, 75000, 96000, 120000)\n",
      "(10.616593658924103, '3166859000', 63000, 105000, 1405000, 1447000)\n",
      "(4.430018126964569, '1534060400', 3000, 24000, 3668000, 3683000)\n",
      "(73.7065578699112, '1629260900', 93000, 179000, 5352000, 5438000)\n",
      "(51.001447439193726, '1601278800', 25000, 81000, 6757000, 6813000)\n",
      "(20.778279781341553, '2666192100', 34000, 82000, 1537000, 1601000)\n",
      "(26.051497995853424, '2367850000', 28000, 79000, 3571000, 3623000)\n",
      "(43.826499819755554, '1887729500', 0, 55000, 2495000, 2551000)\n",
      "(47.443311750888824, '1500872700', 0, 99000, 3441000, 3550000)\n",
      "(65.99086838960648, '1402364300', 36000, 104000, 2235000, 2303000)\n",
      "(10.400666773319244, '1598981800', 57000, 92000, 2683000, 2722000)\n",
      "(5.219767153263092, '1534060400', 74000, 97000, 3671000, 3687000)\n",
      "(8.667783915996552, '2333805400', 63000, 103000, 4858000, 4890000)\n",
      "(46.378190100193024, '3009055500', 2000, 53000, 1413000, 1474000)\n",
      "(8.748582065105438, '2303359200', 92000, 120000, 3114000, 3141000)\n",
      "(4.342910885810852, '1627286600', 17000, 31000, 138000, 156000)\n",
      "(2.6282519698143005, '1398481500', 31000, 34000, 47000, 50000)\n",
      "(53.984080612659454, '2620315400', 32000, 98000, 3945000, 4011000)\n",
      "(12.621381044387817, '1600623900', 38000, 80000, 468000, 512000)\n",
      "(33.809822618961334, '1234417600', 17000, 79000, 2853000, 2937000)\n",
      "(50.233526170253754, '2274699000', 0, 52000, 2139000, 2192000)\n",
      "(37.673711478710175, '2929626300', 45000, 83000, 3347000, 3385000)\n",
      "(90.90127158164978, '1684068900', 56000, 147000, 1163000, 1254000)\n",
      "(70.06904345750809, '1804154000', 9000, 86000, 4394000, 4471000)\n",
      "(34.03557014465332, '1260706600', 54000, 109000, 2264000, 2319000)\n",
      "(6.189080715179443, '1782169900', 33000, 51000, 106000, 117000)\n",
      "(68.13213807344437, '1443620200', 0, 80000, 3680000, 3774000)\n",
      "(15.171736061573029, '1928274600', 107000, 132000, 3127000, 3152000)\n",
      "(34.015252470970154, '2400411900', 73000, 133000, 550000, 611000)\n",
      "(6.113804221153259, '1804132300', 105000, 124000, 1391000, 1408000)\n",
      "(4.361481070518494, '3166859000', 81000, 109000, 59000, 81000)\n",
      "(39.306980311870575, '1443620200', 1000, 87000, 1152000, 1254000)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-1e97fe115a99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr_vid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrefer_vids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mr_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvid2features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr_vid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_dists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_dists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_dists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mr_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_vid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-84-457ebbdb90dd>\u001b[0m in \u001b[0;36mcompute_dists\u001b[0;34m(query_features, refer_features)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munsorted_dists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0msorted_dists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munsorted_dists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;31m# sorted_dists = np.sort(unsorted_dists)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_dists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_query_ans = {}\n",
    "for q_vid in train_query_vids:\n",
    "    q_feat = vid2features[q_vid]\n",
    "    q_baseaddr = train_query_vid2baseaddr[q_vid]\n",
    "    q_ans = []\n",
    "    # 初筛\n",
    "    r_scores = []\n",
    "    for r_vid in refer_vids:\n",
    "        r_feat = vid2features[r_vid]\n",
    "        idxs, unsorted_dists, sorted_dists = compute_dists(q_feat, r_feat)\n",
    "        score = np.sum(sorted_dists[:, 0])\n",
    "        r_scores.append((score, r_vid))\n",
    "    r_scores.sort(key = lambda x: x[0], reverse=False)\n",
    "    # 细筛\n",
    "    top_K = 20\n",
    "    for k, (_, r_vid) in enumerate(r_scores):\n",
    "        if(k >= top_K):\n",
    "            break\n",
    "        r_feat = vid2features[r_vid]\n",
    "        r_baseaddr = refer_vid2baseaddr[r_vid]\n",
    "        path_q, path_r, score = get_frame_alignment(q_feat, r_feat, top_K=3, min_sim=0.85, max_step=10)\n",
    "        if len(path_q) > 0:\n",
    "            time_q = [int(train_query_fid2time[q_baseaddr + qf_id] * 1000) for qf_id in path_q]\n",
    "            time_r = [int(refer_fid2time[r_baseaddr + rf_id] * 1000) for rf_id in path_r]\n",
    "            q_ans.append((score, r_vid, time_q[0], time_q[-1], time_r[0], time_r[-1]))\n",
    "    \n",
    "    q_ans.sort(key = lambda x: x[0], reverse=True)\n",
    "    train_query_ans[q_vid] = q_ans[0][1:]\n",
    "    print(q_ans[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 train.csv\n",
    "train_df = pd.read_csv(TRAIN_PATH + 'train.csv')\n",
    "train_query_label = {}\n",
    "for vid in train_query_vids:\n",
    "    row = train_df.loc[train_df['query_id'] == vid]\n",
    "    time_q = (int(row.iloc[0, 1].split('|')[0]), int(row.iloc[0, 1].split('|')[1]))\n",
    "    time_r = (int(row.iloc[0, 3].split('|')[0]), int(row.iloc[0, 3].split('|')[1]))\n",
    "    train_query_label[vid] = (str(row.iloc[0, 2]), time_q[0], time_q[1], time_r[0], time_r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算分数\n",
    "def compute_precision_recall(y_true, y_pred, pr=False):\n",
    "    \"\"\"\n",
    "      用于计算测试结果的P-R值\n",
    "      Args:\n",
    "        y_true: dict shape: [N, 5]\n",
    "        y_pred: dict shape: [M, 5]\n",
    "        pr: need precision and recall\n",
    "      Returns:\n",
    "        f1_score\n",
    "        precision\n",
    "        recall\n",
    "    \"\"\"\n",
    "    tp = fp = fn = 0\n",
    "    threshold = 3000\n",
    "\n",
    "#    for q_vid in y_true:\n",
    "    for q_vid in y_pred:\n",
    "        q_ans = y_pred[q_vid]\n",
    "        q_label = y_true[q_vid]\n",
    "\n",
    "        if(len(q_ans) == 5):\n",
    "            if(q_ans[0] == q_label[0] and abs(q_ans[1] - q_label[1]) <= threshold and abs(q_ans[2] - q_label[2]) <= threshold \n",
    "            and abs(q_ans[3] - q_label[3]) <= threshold and abs(q_ans[4] - q_label[4]) <= threshold):\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1_score = 2 * precision * recall / (precision + recall)\n",
    "    if(pr):\n",
    "        return f1_score, precision, recall\n",
    "    else:\n",
    "        return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6233766233766235"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_precision_recall(train_query_label, train_query_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (24.256401896476746, '1568027000', 70000, 137000, 455000, 527000)\n"
     ]
    }
   ],
   "source": [
    "# 准备提交\n",
    "test_query_ans = {}\n",
    "for i, q_vid in enumerate(test_query_vids):\n",
    "    q_feat = vid2features[q_vid]\n",
    "    q_baseaddr = test_query_vid2baseaddr[q_vid]\n",
    "    q_ans = []\n",
    "    # 初筛\n",
    "    r_scores = []\n",
    "    for r_vid in refer_vids:\n",
    "        r_feat = vid2features[r_vid]\n",
    "        idxs, unsorted_dists, sorted_dists = compute_dists(q_feat, r_feat)\n",
    "        score = np.sum(sorted_dists[:, 0])\n",
    "        r_scores.append((score, r_vid))\n",
    "    r_scores.sort(key = lambda x: x[0], reverse=False)\n",
    "    # 细筛\n",
    "    top_K = 20\n",
    "    for k, (_, r_vid) in enumerate(r_scores):\n",
    "        if(k >= top_K):\n",
    "            break\n",
    "        r_feat = vid2features[r_vid]\n",
    "        r_baseaddr = refer_vid2baseaddr[r_vid]\n",
    "        path_q, path_r, score = get_frame_alignment(q_feat, r_feat, top_K=3, min_sim=0.85, max_step=10)\n",
    "        if len(path_q) > 0:\n",
    "            time_q = [int(test_query_fid2time[q_baseaddr + qf_id] * 1000) for qf_id in path_q]\n",
    "            time_r = [int(refer_fid2time[r_baseaddr + rf_id] * 1000) for rf_id in path_r]\n",
    "            q_ans.append((score, r_vid, time_q[0], time_q[-1], time_r[0], time_r[-1]))\n",
    "    \n",
    "    q_ans.sort(key = lambda x: x[0], reverse=True)\n",
    "    test_query_ans[q_vid] = q_ans[0][1:]\n",
    "    print(i, q_ans[0])\n",
    "    if i % 10 == 0:\n",
    "        with open(PATH + 'var/test_query_ans_uni.pk', 'wb') as pk_file:\n",
    "            pickle.dump(test_query_ans, pk_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提交一个最简单的结果\n",
    "submit_df = pd.read_csv(TEST_PATH + 'submit_example2.csv')\n",
    "for vid in test_query_vids:\n",
    "    q_pred = test_query_ans[vid]\n",
    "    time_q = str(q_pred[1]) + '|' + str(q_pred[2])\n",
    "    time_r = str(q_pred[3]) + '|' + str(q_pred[4])\n",
    "    submit_df.loc[submit_df['query_id'] == vid, ['query_time_range(ms)', 'refer_id', 'refer_time_range(ms)']] = [time_q, q_pred[0], time_r]\n",
    "\n",
    "submit_df.to_csv(TEST_PATH + 'result2.csv', index = None, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
