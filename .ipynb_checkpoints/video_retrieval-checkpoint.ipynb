{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相似视频检索\n",
    "\n",
    "视频级相似匹配 -> 帧级匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import imagehash\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial.distance import cosine\n",
    "from networkx.algorithms.dag import dag_longest_path\n",
    "\n",
    "PATH = '/home/wx/work/video_copy_detection/'\n",
    "TRAIN_PATH = PATH + 'train/'\n",
    "TEST_PATH = PATH + 'test/'\n",
    "TRAIN_QUERY_PATH = TRAIN_PATH + 'query/'\n",
    "REFER_PATH = TRAIN_PATH + 'refer/'\n",
    "TRAIN_QUERY_FRAME_PATH = TRAIN_PATH + 'query_uniformframe/'\n",
    "REFER_FRAME_PATH = TRAIN_PATH + 'refer_uniformframe/'\n",
    "TEST_QUERY_PATH = TEST_PATH + 'query/'\n",
    "TEST_QUERY_FRAME_PATH = TEST_PATH + 'query_uniformframe/'\n",
    "CODE_DIR = PATH + 'code/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取特征文件\n",
    "with open(PATH + 'var/train_query_features_uni.pk', 'rb') as pk_file:\n",
    "    train_query_features = pickle.load(pk_file)\n",
    "\n",
    "with open(PATH + 'var/test_query_features_uni.pk', 'rb') as pk_file:\n",
    "    test_query_features = pickle.load(pk_file)\n",
    "\n",
    "with open(PATH + 'var/refer_features_uni.pk', 'rb') as pk_file:\n",
    "    refer_features = pickle.load(pk_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375702, 512)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_query_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 train_query 视频的关键帧\n",
    "# 按照视频和关键帧时间进行排序\n",
    "# 预处理工具 dict\n",
    "train_query_imgs_path = []\n",
    "train_query_vids = []\n",
    "train_query_vid2idx = {}\n",
    "train_query_idx2vid = {}\n",
    "train_query_vid2baseaddr = {}\n",
    "train_query_fid2path = {}\n",
    "train_query_fid2vid = {}\n",
    "train_query_fid2time = {}\n",
    "\n",
    "for id in pd.read_csv(TRAIN_PATH + 'train.csv')['query_id']:\n",
    "    train_query_imgs_path += glob.glob(TRAIN_QUERY_FRAME_PATH + id + '/*.jpg')\n",
    "    train_query_vids += [id]\n",
    "\n",
    "train_query_imgs_path.sort(key = lambda x: x.lower())\n",
    "train_query_vids.sort(key = lambda x: x.lower())\n",
    "\n",
    "\n",
    "idx = 0\n",
    "for vid in train_query_vids:\n",
    "    train_query_vid2idx[vid] = idx\n",
    "    train_query_idx2vid[idx] = vid\n",
    "    idx += 1\n",
    "fid = 0\n",
    "pre_vid = \"\"\n",
    "cur_base = 0\n",
    "for idx, path in enumerate(train_query_imgs_path):\n",
    "    cur_vid = path.split('/')[-1][:-20]\n",
    "    train_query_fid2vid[fid] = cur_vid\n",
    "    train_query_fid2path[fid] = path\n",
    "    train_query_fid2time[fid] = float(path.split('/')[-1].split('_')[-1][:-4])\n",
    "    if pre_vid != cur_vid:\n",
    "        cur_base = idx\n",
    "        pre_vid = cur_vid\n",
    "    train_query_vid2baseaddr[cur_vid] = cur_base\n",
    "    fid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path.split('/')[-1][:-20]\n",
    "# float(path.split('/')[-1].split('_')[-1][:-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 test_query 视频的关键帧\n",
    "# 按照视频和关键帧时间进行排序\n",
    "# 预处理工具 dict\n",
    "test_query_imgs_path = []\n",
    "test_query_vids = []\n",
    "test_query_vid2idx = {}\n",
    "test_query_idx2vid = {}\n",
    "test_query_vid2baseaddr = {}\n",
    "test_query_fid2path = {}\n",
    "test_query_fid2vid = {}\n",
    "test_query_fid2time = {}\n",
    "\n",
    "for id in pd.read_csv(TEST_PATH + 'submit_example.csv')['query_id']:\n",
    "    test_query_imgs_path += glob.glob(TEST_QUERY_FRAME_PATH + id + '/*.jpg')\n",
    "    test_query_vids += [id]\n",
    "\n",
    "test_query_imgs_path.sort(key = lambda x: x.lower())\n",
    "test_query_vids.sort(key = lambda x: x.lower())\n",
    "\n",
    "idx = 0\n",
    "for vid in test_query_vids:\n",
    "    test_query_vid2idx[vid] = idx\n",
    "    test_query_idx2vid[idx] = vid\n",
    "    idx += 1\n",
    "fid = 0\n",
    "pre_vid = \"\"\n",
    "cur_base = 0\n",
    "for idx, path in enumerate(test_query_imgs_path):\n",
    "    cur_vid = path.split('/')[-1][:-20]\n",
    "    test_query_fid2vid[fid] = cur_vid\n",
    "    test_query_fid2path[fid] = path\n",
    "    test_query_fid2time[fid] = float(path.split('/')[-1].split('_')[-1][:-4])\n",
    "    if pre_vid != cur_vid:\n",
    "        cur_base = idx\n",
    "        pre_vid = cur_vid\n",
    "    test_query_vid2baseaddr[cur_vid] = cur_base\n",
    "    fid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 refer_query 视频的关键帧\n",
    "# 按照视频和关键帧时间进行排序\n",
    "# 预处理工具 dict\n",
    "\n",
    "refer_imgs_path = glob.glob(REFER_FRAME_PATH + '*/*.jpg')\n",
    "refer_imgs_path.sort(key = lambda x: x.lower())\n",
    "\n",
    "refer_vids = []\n",
    "refer_vid2idx = {}\n",
    "refer_idx2vid = {}\n",
    "refer_vid2baseaddr = {}\n",
    "refer_fid2path = {}\n",
    "refer_fid2vid = {}\n",
    "refer_fid2time = {}\n",
    "\n",
    "for path in refer_imgs_path:\n",
    "    vid = path.split('/')[-2]\n",
    "    refer_vids += [vid]\n",
    "\n",
    "refer_vids = list(set(refer_vids))\n",
    "refer_vids.sort(key = lambda x: x.lower())\n",
    "\n",
    "idx = 0\n",
    "for vid in refer_vids:\n",
    "    refer_vid2idx[vid] = idx\n",
    "    refer_idx2vid[idx] = vid\n",
    "    idx += 1\n",
    "fid = 0\n",
    "pre_vid = \"\"\n",
    "cur_base = 0\n",
    "for idx, path in enumerate(refer_imgs_path):\n",
    "    cur_vid = path.split('/')[-1][:-20]\n",
    "    refer_fid2vid[fid] = cur_vid\n",
    "    refer_fid2path[fid] = path\n",
    "    refer_fid2time[fid] = float(path.split('/')[-1].split('_')[-1][:-4])\n",
    "    if pre_vid != cur_vid:\n",
    "        cur_base = idx\n",
    "        pre_vid = cur_vid\n",
    "    refer_vid2baseaddr[cur_vid] = cur_base\n",
    "    fid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids = np.concatenate((train_query_vids, test_query_vids, refer_vids), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375702it [00:08, 46285.43it/s]\n",
      "188807it [00:03, 47332.15it/s]\n",
      "749516it [01:10, 10650.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# 特征按视频归类\n",
    "if True:\n",
    "    vid2features = {}\n",
    "    for (path, cur_feat) in tqdm(zip(train_query_imgs_path, train_query_features)):\n",
    "        vid = path.split('/')[-2]\n",
    "        if(not vid in vid2features):\n",
    "            vid2features[vid] = [cur_feat]\n",
    "        else:\n",
    "            vid2features[vid] = np.concatenate((vid2features[vid], [cur_feat]), axis=0)\n",
    "\n",
    "    for (path, cur_feat) in tqdm(zip(test_query_imgs_path, test_query_features)):\n",
    "        vid = path.split('/')[-2]\n",
    "        if(not vid in vid2features):\n",
    "            vid2features[vid] = [cur_feat]\n",
    "        else:\n",
    "            vid2features[vid] = np.concatenate((vid2features[vid], [cur_feat]), axis=0)\n",
    "\n",
    "    for (path, cur_feat) in tqdm(zip(refer_imgs_path, refer_features)):\n",
    "        vid = path.split('/')[-2]\n",
    "        if(not vid in vid2features):\n",
    "            vid2features[vid] = [cur_feat]\n",
    "        else:\n",
    "            vid2features[vid] = np.concatenate((vid2features[vid], [cur_feat]), axis=0)\n",
    "    \n",
    "    with open(PATH + 'var/vid2features_uni.pk', 'wb') as pk_file:\n",
    "        pickle.dump(vid2features, pk_file)\n",
    "else:\n",
    "    with open(PATH + 'var/vid2features_uni.pk', 'rb') as pk_file:\n",
    "        vid2features = pickle.load(pk_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 512)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid2features[refer_vids[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarities(query_features, refer_features):\n",
    "    \"\"\"\n",
    "      用于计算两组特征(已经做过l2-norm)之间的相似度\n",
    "      Args:\n",
    "        query_features: shape: [N, D]\n",
    "        refer_features: shape: [M, D]\n",
    "      Returns:\n",
    "        sorted_sims: shape: [N, M]\n",
    "        unsorted_sims: shape: [N, M]\n",
    "    \"\"\"\n",
    "    sorted_sims = []\n",
    "    unsorted_sims = []\n",
    "    # 计算待查询视频和所有视频的距离\n",
    "    dist = np.nan_to_num(cdist(query_features, refer_features, metric='cosine'))\n",
    "    for i, v in enumerate(query_features):\n",
    "        # 归一化，将距离转化成相似度\n",
    "        # sim = np.round(1 - dist[i] / dist[i].max(), decimals=6)\n",
    "        sim = 1 - dist[i]\n",
    "        # 按照相似度的从大到小排列，输出index\n",
    "        unsorted_sims += [sim]\n",
    "        sorted_sims += [[(s, sim[s]) for s in sim.argsort()[::-1] if not np.isnan(sim[s])]]\n",
    "    return sorted_sims, unsorted_sims\n",
    "\n",
    "def compute_dists(query_features, refer_features):\n",
    "    \"\"\"\n",
    "      用于计算两组特征(已经做过l2-norm)之间的余弦距离\n",
    "      Args:\n",
    "        query_features: shape: [N, D]\n",
    "        refer_features: shape: [M, D]\n",
    "      Returns:\n",
    "        idxs: shape [N, M]\n",
    "        unsorted_dists: shape: [N, M]\n",
    "        sorted_dists: shape: [N, M]\n",
    "    \"\"\"\n",
    "    sims = np.dot(query_features, refer_features.T)\n",
    "    unsorted_dists = 1 - sims # sort 不好改降序\n",
    "    # unsorted_dist = np.nan_to_num(cdist(query_features, refer_features, metric='cosine'))\n",
    "    idxs = np.argsort(unsorted_dists)\n",
    "    rows = np.dot(np.arange(idxs.shape[0]).reshape((idxs.shape[0], 1)), np.ones((1, idxs.shape[1]))).astype(int)\n",
    "    sorted_dists = unsorted_dists[rows, idxs]\n",
    "    # sorted_dists = np.sort(unsorted_dists)\n",
    "    return idxs, unsorted_dists, sorted_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_alignment(query_features, refer_features, top_K=5, min_sim=0.80, max_step=10):\n",
    "    \"\"\"\n",
    "      用于计算两组特征(已经做过l2-norm)之间的帧匹配结果\n",
    "      Args:\n",
    "        query_features: shape: [N, D]\n",
    "        refer_features: shape: [M, D]\n",
    "        top_K: 取前K个refer_frame\n",
    "        min_sim: 要求query_frame与refer_frame的最小相似度\n",
    "        max_step: 有边相连的结点间的最大步长\n",
    "      Returns:\n",
    "        path_query: shape: [1, L]\n",
    "        path_refer: shape: [1, L]\n",
    "    \"\"\"\n",
    "    node_pair2id = {}\n",
    "    node_id2pair = {}\n",
    "    node_id2pair[0] = (-1, -1) # source\n",
    "    node_pair2id[(-1, -1)] = 0\n",
    "    node_num = 1\n",
    "\n",
    "    DG = nx.DiGraph()\n",
    "    DG.add_node(0)\n",
    "\n",
    "    idxs, unsorted_dists, sorted_dists = compute_dists(query_features, refer_features)\n",
    "\n",
    "    # add nodes\n",
    "    for qf_idx in range(query_features.shape[0]):\n",
    "        for k in range(top_K):\n",
    "            rf_idx = idxs[qf_idx][k]\n",
    "            sim = 1 - sorted_dists[qf_idx][k]\n",
    "            if sim < min_sim:\n",
    "                break\n",
    "            node_id2pair[node_num] = (qf_idx, rf_idx)\n",
    "            node_pair2id[(qf_idx, rf_idx)] = node_num\n",
    "            DG.add_node(node_num)\n",
    "            node_num += 1\n",
    "    \n",
    "    node_id2pair[node_num] = (query_features.shape[0], refer_features.shape[0]) # sink\n",
    "    node_pair2id[(query_features.shape[0], refer_features.shape[0])] = node_num\n",
    "    DG.add_node(node_num)\n",
    "    node_num += 1\n",
    "\n",
    "    # link nodes\n",
    "\n",
    "    for i in range(0, node_num - 1):\n",
    "        for j in range(i + 1, node_num - 1):\n",
    "            \n",
    "            pair_i = node_id2pair[i]\n",
    "            pair_j = node_id2pair[j]\n",
    "\n",
    "            if(pair_j[0] > pair_i[0] and pair_j[1] > pair_i[1] and\n",
    "               pair_j[0] - pair_i[0] <= max_step and pair_j[1] - pair_i[1] <= max_step):\n",
    "               qf_idx = pair_j[0]\n",
    "               rf_idx = pair_j[1]\n",
    "               DG.add_edge(i, j, weight=1 - unsorted_dists[qf_idx][rf_idx])\n",
    "\n",
    "    for i in range(0, node_num - 1):\n",
    "        j = node_num - 1\n",
    "\n",
    "        pair_i = node_id2pair[i]\n",
    "        pair_j = node_id2pair[j]\n",
    "\n",
    "        if(pair_j[0] > pair_i[0] and pair_j[1] > pair_i[1] and\n",
    "            pair_j[0] - pair_i[0] <= max_step and pair_j[1] - pair_i[1] <= max_step):\n",
    "            qf_idx = pair_j[0]\n",
    "            rf_idx = pair_j[1]\n",
    "            DG.add_edge(i, j, weight=0)\n",
    "\n",
    "    longest_path = dag_longest_path(DG)\n",
    "    if 0 in longest_path:\n",
    "        longest_path.remove(0) # remove source node\n",
    "    if node_num - 1 in longest_path:\n",
    "        longest_path.remove(node_num - 1) # remove sink node\n",
    "    path_query = [node_id2pair[node_id][0] for node_id in longest_path]\n",
    "    path_refer = [node_id2pair[node_id][1] for node_id in longest_path]\n",
    "\n",
    "    score = 0.0\n",
    "    for (qf_idx, rf_idx) in zip(path_query, path_refer):\n",
    "        score += 1 - unsorted_dists[qf_idx][rf_idx]\n",
    "\n",
    "    return path_query, path_refer, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totally cost 0.10426568984985352\n"
     ]
    }
   ],
   "source": [
    "time_start=time.time()\n",
    "qf = vid2features[train_query_vids[0]]\n",
    "rf = vid2features['1226686400']\n",
    "idxs, unsorted_dists, sorted_dists = compute_dists(qf, rf)\n",
    "time_end=time.time()\n",
    "print('totally cost',time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_time_range(ms): 58000|80000\n",
      "refer_time_range(ms): 3228000|3249000\n",
      "score: 7.64414119720459\n",
      "                                  query_id query_time_range(ms)    refer_id  \\\n",
      "1308  00530630-b8c8-11e9-930e-fa163ee49799         48290|116410  3184886800   \n",
      "\n",
      "     refer_time_range(ms)  \n",
      "1308      3217530|3285650  \n",
      "totally cost 0.2189311981201172\n"
     ]
    }
   ],
   "source": [
    "time_start=time.time()\n",
    "q_vid = '00530630-b8c8-11e9-930e-fa163ee49799'\n",
    "r_vid = '3184886800'\n",
    "query = vid2features[q_vid]\n",
    "refer = vid2features[r_vid]\n",
    "q_baseaddr = train_query_vid2baseaddr[q_vid]\n",
    "r_baseaddr = refer_vid2baseaddr[r_vid]\n",
    "path_query, path_refer, score = get_frame_alignment(query, refer) # local address\n",
    "\n",
    "time_query = [int(train_query_fid2time[q_baseaddr + qf_id] * 1000) for qf_id in path_query]\n",
    "time_refer = [int(refer_fid2time[r_baseaddr + rf_id] * 1000) for rf_id in path_refer]\n",
    "print(\"query_time_range(ms): {}|{}\".format(time_query[0], time_query[-1]))\n",
    "print(\"refer_time_range(ms): {}|{}\".format(time_refer[0], time_refer[-1]))\n",
    "print(\"score: {}\".format(score))\n",
    "#print(time_query)\n",
    "#print(time_refer)\n",
    "train_df = pd.read_csv(TRAIN_PATH + 'train.csv')\n",
    "print(train_df.loc[train_df['query_id'] == q_vid])\n",
    "time_end=time.time()\n",
    "print('totally cost',time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs, unsorted_dists, sorted_dists = compute_dists(vid2features[q_vid], vid2features[r_vid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "'''\n",
    "for i in range(len(sorted_dists)):\n",
    "    print(i)\n",
    "    for j in range(5):\n",
    "        print(idxs[i][j], 1-sorted_dists[i][j])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63.166347086429596, '1224903000', 93000, 176000, 487000, 576000)\n",
      "(52.036120772361755, '2274916400', 18000, 87000, 1284000, 1353000)\n",
      "(64.52273601293564, '1356122300', 1000, 70000, 344000, 412000)\n",
      "(50.6969398856163, '1398481500', 1000, 61000, 810000, 869000)\n",
      "(40.43487071990967, '2509505900', 83000, 150000, 1037000, 1110000)\n",
      "(14.831205308437347, '1498995700', 64000, 114000, 4065000, 4092000)\n",
      "(31.852342069149017, '2666192100', 29000, 65000, 4543000, 4594000)\n",
      "(72.67287486791611, '1176745900', 1000, 80000, 1290000, 1369000)\n",
      "(53.64362645149231, '1615774200', 33000, 93000, 689000, 761000)\n",
      "(15.776481747627258, '1374493200', 12000, 80000, 2494000, 2539000)\n",
      "(41.260876059532166, '1332713900', 22000, 102000, 1982000, 2070000)\n",
      "(73.85776668787003, '2436435900', 8000, 87000, 1167000, 1246000)\n",
      "(40.796204805374146, '2342638000', 1000, 51000, 6825000, 6876000)\n",
      "(33.002986550331116, '1952297000', 48000, 94000, 466000, 540000)\n",
      "(38.926399767398834, '1596058300', 1000, 68000, 429000, 506000)\n",
      "(67.98666650056839, '1723849300', 53000, 121000, 2481000, 2549000)\n",
      "(48.84355962276459, '3043930400', 1000, 50000, 1156000, 1217000)\n",
      "(32.370310723781586, '2845332600', 1000, 51000, 3461000, 3510000)\n",
      "(12.13968288898468, '1500744900', 5000, 39000, 56000, 94000)\n",
      "(56.92626094818115, '3203967000', 1000, 62000, 1273000, 1345000)\n",
      "(77.95739656686783, '2342638000', 1000, 106000, 1509000, 1612000)\n",
      "(20.811039745807648, '1534060400', 25000, 112000, 3668000, 3739000)\n",
      "(40.52948784828186, '3166859000', 43000, 136000, 1385000, 1478000)\n",
      "(17.58143776655197, '1534060400', 1000, 104000, 3667000, 3739000)\n",
      "(79.22164863348007, '1629260900', 94000, 181000, 5353000, 5449000)\n",
      "(53.51625394821167, '1601278800', 26000, 82000, 6758000, 6814000)\n",
      "(38.40728670358658, '2829817400', 35000, 84000, 1502000, 1604000)\n",
      "(32.95375311374664, '2367850000', 29000, 80000, 3572000, 3624000)\n",
      "(48.98295348882675, '1887729500', 1000, 56000, 2496000, 2552000)\n",
      "(64.02335894107819, '1500872700', 1000, 100000, 3439000, 3551000)\n",
      "(66.85352611541748, '1402364300', 37000, 105000, 2236000, 2304000)\n",
      "(22.769910216331482, '1534060400', 12000, 107000, 3667000, 3739000)\n",
      "(23.093316972255707, '1488395400', 1000, 98000, 528000, 569000)\n",
      "(17.576405882835388, '407146000', 46000, 136000, 621000, 676000)\n",
      "(47.20225238800049, '3009055500', 3000, 54000, 1414000, 1475000)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-51c86f7fb86a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr_vid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrefer_vids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mr_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvid2features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr_vid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_dists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_dists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_dists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mr_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_vid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-457ebbdb90dd>\u001b[0m in \u001b[0;36mcompute_dists\u001b[0;34m(query_features, refer_features)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munsorted_dists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0msorted_dists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munsorted_dists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;31m# sorted_dists = np.sort(unsorted_dists)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_dists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_query_ans = {}\n",
    "for q_vid in train_query_vids:\n",
    "    q_feat = vid2features[q_vid]\n",
    "    q_baseaddr = train_query_vid2baseaddr[q_vid]\n",
    "    q_ans = []\n",
    "    # 初筛\n",
    "    r_scores = []\n",
    "    for r_vid in refer_vids:\n",
    "        r_feat = vid2features[r_vid]\n",
    "        idxs, unsorted_dists, sorted_dists = compute_dists(q_feat, r_feat)\n",
    "        score = np.sum(sorted_dists[:, 0])\n",
    "        r_scores.append((score, r_vid))\n",
    "    r_scores.sort(key = lambda x: x[0], reverse=False)\n",
    "    # 细筛\n",
    "    top_K = 20\n",
    "    for k, (_, r_vid) in enumerate(r_scores):\n",
    "        if(k >= top_K):\n",
    "            break\n",
    "        r_feat = vid2features[r_vid]\n",
    "        r_baseaddr = refer_vid2baseaddr[r_vid]\n",
    "        path_q, path_r, score = get_frame_alignment(q_feat, r_feat, top_K=5, min_sim=0.80, max_step=10)\n",
    "        if len(path_q) > 0:\n",
    "            time_q = [int(train_query_fid2time[q_baseaddr + qf_id] * 1000) for qf_id in path_q]\n",
    "            time_r = [int(refer_fid2time[r_baseaddr + rf_id] * 1000) for rf_id in path_r]\n",
    "            q_ans.append((score, r_vid, time_q[0], time_q[-1], time_r[0], time_r[-1]))\n",
    "    \n",
    "    q_ans.sort(key = lambda x: x[0], reverse=True)\n",
    "    train_query_ans[q_vid] = q_ans[0][1:]\n",
    "    print(q_ans[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 train.csv\n",
    "train_df = pd.read_csv(TRAIN_PATH + 'train.csv')\n",
    "train_query_label = {}\n",
    "for vid in train_query_vids:\n",
    "    row = train_df.loc[train_df['query_id'] == vid]\n",
    "    time_q = (int(row.iloc[0, 1].split('|')[0]), int(row.iloc[0, 1].split('|')[1]))\n",
    "    time_r = (int(row.iloc[0, 3].split('|')[0]), int(row.iloc[0, 3].split('|')[1]))\n",
    "    train_query_label[vid] = (str(row.iloc[0, 2]), time_q[0], time_q[1], time_r[0], time_r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算分数\n",
    "def compute_precision_recall(y_true, y_pred, pr=False):\n",
    "    \"\"\"\n",
    "      用于计算测试结果的P-R值\n",
    "      Args:\n",
    "        y_true: dict shape: [N, 5]\n",
    "        y_pred: dict shape: [M, 5]\n",
    "        pr: need precision and recall\n",
    "      Returns:\n",
    "        f1_score\n",
    "        precision\n",
    "        recall\n",
    "    \"\"\"\n",
    "    tp = fp = fn = 0\n",
    "    threshold = 5000\n",
    "\n",
    "#    for q_vid in y_true:\n",
    "    for q_vid in y_pred:\n",
    "        q_ans = y_pred[q_vid]\n",
    "        q_label = y_true[q_vid]\n",
    "\n",
    "        if(len(q_ans) == 5):\n",
    "            if(q_ans[0] == q_label[0] and abs(q_ans[1] - q_label[1]) <= threshold and abs(q_ans[2] - q_label[2]) <= threshold \n",
    "            and abs(q_ans[3] - q_label[3]) <= threshold and abs(q_ans[4] - q_label[4]) <= threshold):\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1_score = 2 * precision * recall / (precision + recall)\n",
    "    if(pr):\n",
    "        return f1_score, precision, recall\n",
    "    else:\n",
    "        return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6538461538461539"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_precision_recall(train_query_label, train_query_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备提交\n",
    "test_query_ans = {}\n",
    "for i, q_vid in enumerate(test_query_vids):\n",
    "    q_feat = vid2features[q_vid]\n",
    "    q_baseaddr = test_query_vid2baseaddr[q_vid]\n",
    "    q_ans = []\n",
    "    # 初筛\n",
    "    r_scores = []\n",
    "    for r_vid in refer_vids:\n",
    "        r_feat = vid2features[r_vid]\n",
    "        idxs, unsorted_dists, sorted_dists = compute_dists(q_feat, r_feat)\n",
    "        score = np.sum(sorted_dists[:, 0])\n",
    "        r_scores.append((score, r_vid))\n",
    "    r_scores.sort(key = lambda x: x[0], reverse=False)\n",
    "    # 细筛\n",
    "    top_K = 20\n",
    "    for k, (_, r_vid) in enumerate(r_scores):\n",
    "        if(k >= top_K):\n",
    "            break\n",
    "        r_feat = vid2features[r_vid]\n",
    "        r_baseaddr = refer_vid2baseaddr[r_vid]\n",
    "        path_q, path_r, score = get_frame_alignment(q_feat, r_feat, top_K=5, min_sim=0.80, max_step=10)\n",
    "        if len(path_q) > 0:\n",
    "            time_q = [int(test_query_fid2time[q_baseaddr + qf_id] * 1000) for qf_id in path_q]\n",
    "            time_r = [int(refer_fid2time[r_baseaddr + rf_id] * 1000) for rf_id in path_r]\n",
    "            q_ans.append((score, r_vid, time_q[0], time_q[-1], time_r[0], time_r[-1]))\n",
    "    \n",
    "    q_ans.sort(key = lambda x: x[0], reverse=True)\n",
    "    test_query_ans[q_vid] = q_ans[0][1:]\n",
    "    print(i, q_ans[0])\n",
    "    if i % 10 == 0:\n",
    "        with open(PATH + 'var/test_query_ans_uni.pk', 'wb') as pk_file:\n",
    "            pickle.dump(test_query_ans, pk_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提交一个最简单的结果\n",
    "submit_df = pd.read_csv(TEST_PATH + 'submit_example.csv')\n",
    "for vid in test_query_vids:\n",
    "    q_pred = test_query_ans[vid]\n",
    "    time_q = str(q_pred[1]) + '|' + str(q_pred[2])\n",
    "    time_r = str(q_pred[3]) + '|' + str(q_pred[4])\n",
    "    submit_df.loc[submit_df['query_id'] == vid, ['query_time_range(ms)', 'refer_id', 'refer_time_range(ms)']] = [time_q, q_pred[0], time_r]\n",
    "\n",
    "submit_df.to_csv(TEST_PATH + 'result.csv', index = None, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
