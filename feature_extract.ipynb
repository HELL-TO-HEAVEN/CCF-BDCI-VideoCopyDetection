{"cells":[{"cell_type":"markdown","metadata":{},"source":["## 特征提取"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":"import os, sys, codecs\nimport glob\nimport pandas as pd\nimport numpy as np\nimport pickle\nfrom PIL import Image\nfrom tqdm import tqdm_notebook\n\nimport cv2\n\nfrom sklearn.preprocessing import normalize as sknormalize\nfrom sklearn.decomposition import PCA\n\nimport torch\ntorch.manual_seed(0)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data.dataset import Dataset\n\nimport logging\nlogging.basicConfig(level = logging.DEBUG, filename = 'example.log',\n                    format = '%(asctime)s - %(filename)s[line:%(lineno)d]: %(message)s')  # \n\nPATH = '/home/wx/work/video_copy_detection/'\nTRAIN_PATH = PATH + 'train/'\nTEST_PATH = PATH + 'test/'\nQUERY_PATH = TRAIN_PATH + 'query/'\nREFER_PATH = TRAIN_PATH + 'refer/'\nQUERY_FRAME_PATH = TRAIN_PATH + 'query_frame/'\nREFER_FRAME_PATH = TRAIN_PATH + 'refer_frame/'\nTEST_QUERY_PATH = TEST_PATH + 'query/'\nTEST_QUERY_FRAME_PATH = TEST_PATH + 'query_frame/'\nCODE_DIR = PATH + 'code/'"},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":"class QRDataset(Dataset):\n    def __init__(self, img_path, transform = None):\n        self.img_path = img_path\n\n        self.img_label = np.zeros(len(img_path))\n    \n        if transform is not None:\n            self.transform = transform\n        else:\n            self.transform = None\n    \n    def __getitem__(self, index):\n        img = Image.open(self.img_path[index])\n        \n        if self.transform is not None:\n            img = self.transform(img)\n        \n        return img, self.img_path[index]\n\n    def __len__(self):\n        return len(self.img_path)\n    \nmodel = models.resnet18(pretrained = True).cuda()\n\ndef extract_feature(path):\n    if not isinstance(path, list):\n        path = [path]\n    \n    data_loader = torch.utils.data.DataLoader(\n        QRDataset(path, \n                transforms.Compose([\n                            transforms.Resize((224, 224)),\n                            transforms.ToTensor(),\n                            # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n            ])\n        ), batch_size = 40, shuffle = False, num_workers = 16,\n    )\n    \n    img_feature = []\n    with torch.no_grad():\n        for batch_data in tqdm_notebook(data_loader):\n            batch_x, batch_y = batch_data\n            \n            # print(batch_y[:10])\n            batch_x = Variable(batch_x).cuda()\n            feature_pred = model(batch_x)\n\n            # max-pooling\n            # feature_pred = F.max_pool2d(feature_pred, kernel_size=(24, 32))\n            \n            # ave-pooling\n            # feature_pred = F.avg_pool2d(feature_pred, kernel_size=(24, 32))[:, :, 0, 0]\n            \n            #print(feature_pred.shape, batch_x.shape)\n            feature_pred = feature_pred.data.cpu().numpy()\n            # feature_pred = feature_pred.max(-1).max(-1)\n            \n            # feature_pred = feature_pred.reshape((-1, 512))\n            img_feature.append(feature_pred)\n            \n            del feature_pred\n            # img_feature.append(feature_pred)\n            \n    img_feature = np.vstack(img_feature)\n    return img_feature"},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":"# 读取 query 视频的关键帧，并按照视频和关键帧时间进行排序\ntest_query_imgs_path = []\nfor id in pd.read_csv(TEST_PATH + 'submit_example.csv')['query_id']:\n    test_query_imgs_path += glob.glob(TEST_QUERY_FRAME_PATH + id + '/*.jpg')\n\ntest_query_imgs_path.sort(key = lambda x: x.lower())"},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":"# 读取refer视频的关键帧，并按照视频和关键帧时间进行排序\n\nrefer_imgs_path = glob.glob(REFER_FRAME_PATH + '*/*.jpg')\nrefer_imgs_path.sort(key = lambda x: x.lower())"},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40ebca0383c04c0a86d0b67bff88ae76","version_major":2,"version_minor":0},"text/plain":"HBox(children=(IntProgress(value=0, max=1564), HTML(value='')))"},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":"\n"}],"source":"# 抽取query关键帧特征\ntest_query_features = extract_feature(test_query_imgs_path[:])"},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66e7525c9d624febac2f79e56a75692c","version_major":2,"version_minor":0},"text/plain":"HBox(children=(IntProgress(value=0, max=4527), HTML(value='')))"},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":"\n"}],"source":"# 抽取refer关键帧特征\nrefer_features = extract_feature(list(refer_imgs_path[:]))"},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":"def normalize(x, copy = False):\n    \"\"\"\n    A helper function that wraps the function of the same name in sklearn.\n    This helper handles the case of a single column vector.\n    \"\"\"\n    if type(x) == np.ndarray and len(x.shape) == 1:\n        return np.squeeze(sknormalize(x.reshape(1,-1), copy = copy))\n        #return np.squeeze(x / np.sqrt((x ** 2).sum(-1))[..., np.newaxis])\n    else:\n        return sknormalize(x, copy = copy)\n        #return x / np.sqrt((x ** 2).sum(-1))[..., np.newaxis]"},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":"# 特征归一化\n\ntest_query_features = normalize(test_query_features)\nrefer_features = normalize(refer_features)"},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":"# 保存query关键帧特征\n\nwith open(PATH + 'var/test_query_features.txt', 'wb') as f:\n    pickle.dump(test_query_features, f)"},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":"# 保存refer关键帧特征\n\nwith open(PATH + 'var/refer_features.txt', 'wb') as f:\n    pickle.dump(refer_features, f)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}