{"cells":[{"cell_type":"markdown","metadata":{},"source":["## 特征提取"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"import os, sys, codecs\nimport glob\nimport pandas as pd\nimport numpy as np\nimport pickle\nfrom PIL import Image\nfrom tqdm import tqdm\n\nimport cv2\n\nfrom sklearn.preprocessing import normalize as sknormalize\nfrom sklearn.decomposition import PCA\n\nimport torch\ntorch.manual_seed(0)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data.dataset import Dataset\n\nimport logging\nlogging.basicConfig(level = logging.DEBUG, filename = 'example.log',\n                    format = '%(asctime)s - %(filename)s[line:%(lineno)d]: %(message)s')  # \n\nPATH = '/home/wx/work/video_copy_detection/'\nTRAIN_PATH = PATH + 'train/'\nTEST_PATH = PATH + 'test/'\nTRAIN_QUERY_PATH = TRAIN_PATH + 'query/'\nREFER_PATH = TRAIN_PATH + 'refer/'\nTRAIN_QUERY_FRAME_PATH = TRAIN_PATH + 'query_frame/'\nREFER_FRAME_PATH = TRAIN_PATH + 'refer_frame/'\nTEST_QUERY_PATH = TEST_PATH + 'query/'\nTEST_QUERY_FRAME_PATH = TEST_PATH + 'query_frame/'\nCODE_DIR = PATH + 'code/'"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"class QRDataset(Dataset):\n    def __init__(self, img_path, transform = None):\n        self.img_path = img_path\n\n        self.img_label = np.zeros(len(img_path))\n    \n        if transform is not None:\n            self.transform = transform\n        else:\n            self.transform = None\n    \n    def __getitem__(self, index):\n        img = Image.open(self.img_path[index])\n        \n        if self.transform is not None:\n            img = self.transform(img)\n        \n        return img, self.img_path[index]\n\n    def __len__(self):\n        return len(self.img_path)\n# 比res50效果好一些\nmodel = models.resnet18(pretrained = True)\n# res18 bolck.expansion = 1\nmodel.fc = nn.Linear(512, 1024)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\ntransformer = transforms.Compose([\n    transforms.Resize((224, 224)), \n    transforms.ToTensor(),\n    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n\ndef extract_feature(path):\n    if not isinstance(path, list):\n        path = [path]\n    \n    data_loader = torch.utils.data.DataLoader(\n        QRDataset(path, transformer), batch_size = 40, shuffle = False, num_workers = 16)\n\n    img_feature = []\n    with torch.no_grad():\n        for batch_data in tqdm(data_loader):\n            batch_x, batch_y = batch_data\n            \n            batch_x = Variable(batch_x, requires_grad = False).cuda()\n            feature_pred = model(batch_x)\n\n            # max-pooling\n            # feature_pred = F.max_pool2d(feature_pred, kernel_size=(24, 32))\n            \n            # ave-pooling\n            # feature_pred = F.avg_pool2d(feature_pred, kernel_size=(24, 32))[:, :, 0, 0]\n            \n            #print(feature_pred.shape, batch_x.shape)\n            feature_pred = feature_pred.data.cpu().numpy()\n            # feature_pred = feature_pred.max(-1).max(-1)\n            \n            # feature_pred = feature_pred.reshape((-1, 512))\n            img_feature.append(feature_pred)\n            \n            del feature_pred\n            # img_feature.append(feature_pred)\n            \n    img_feature = np.vstack(img_feature)\n    return img_feature"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"# 读取 test_query 视频的关键帧，并按照视频和关键帧时间进行排序\ntest_query_imgs_path = []\nfor id in pd.read_csv(TEST_PATH + 'submit_example.csv')['query_id']:\n    test_query_imgs_path += glob.glob(TEST_QUERY_FRAME_PATH + id + '/*.jpg')\n\ntest_query_imgs_path.sort(key = lambda x: x.lower())"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"# 读取 train_query 视频的关键帧，并按照视频和关键帧时间进行排序\ntrain_query_imgs_path = []\nfor id in pd.read_csv(TRAIN_PATH + 'train.csv')['query_id']:\n    train_query_imgs_path += glob.glob(TRAIN_QUERY_FRAME_PATH + id + '/*.jpg')\n\ntrain_query_imgs_path.sort(key = lambda x: x.lower())"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"# 读取 refer 视频的关键帧，并按照视频和关键帧时间进行排序\n\nrefer_imgs_path = glob.glob(REFER_FRAME_PATH + '*/*.jpg')\nrefer_imgs_path.sort(key = lambda x: x.lower())"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"100%|██████████| 1564/1564 [01:05<00:00, 23.71it/s]\n"}],"source":"# 抽取 test_query 关键帧特征\ntest_query_features = extract_feature(test_query_imgs_path[:])"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"100%|██████████| 3128/3128 [02:12<00:00, 23.57it/s]\n"}],"source":"# 抽取 train_query 关键帧特征\ntrain_query_features = extract_feature(train_query_imgs_path[:])"},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"100%|██████████| 4527/4527 [03:17<00:00, 22.91it/s]\n"}],"source":"# 抽取 refer 关键帧特征\nrefer_features = extract_feature(list(refer_imgs_path[:]))"},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":"def normalize(x, copy = False):\n    \"\"\"\n    A helper function that wraps the function of the same name in sklearn.\n    This helper handles the case of a single column vector.\n    \"\"\"\n    if type(x) == np.ndarray and len(x.shape) == 1:\n        return np.squeeze(sknormalize(x.reshape(1, -1), copy = copy))\n        #return np.squeeze(x / np.sqrt((x ** 2).sum(-1))[..., np.newaxis])\n    else:\n        return sknormalize(x, copy = copy)\n        #return x / np.sqrt((x ** 2).sum(-1))[..., np.newaxis]"},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":"'\\npca = PCA(n_components=512)\\n\\ntrain_query_features = pca.fit_transform(train_query_features)\\ntest_query_features = pca.fit_transform(test_query_features)\\nrefer_features = pca.fit_transform(refer_features)\\n'"},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":"# PCA 降维\n'''\npca = PCA(n_components=512)\n\ntrain_query_features = pca.fit_transform(train_query_features)\ntest_query_features = pca.fit_transform(test_query_features)\nrefer_features = pca.fit_transform(refer_features)\n'''"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":"# L2正则化\ntrain_query_features = normalize(train_query_features)\ntest_query_features = normalize(test_query_features)\nrefer_features = normalize(refer_features)"},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":"# 保存 test_query 关键帧特征\n\nwith open(PATH + 'var/test_query_features.pk', 'wb') as pk_file:\n    pickle.dump(test_query_features, pk_file)"},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":"# 保存 train_query 关键帧特征\n\nwith open(PATH + 'var/train_query_features.pk', 'wb') as pk_file:\n    pickle.dump(train_query_features, pk_file)"},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":"# 保存 refer 关键帧特征\n\nwith open(PATH + 'var/refer_features.pk', 'wb') as pk_file:\n    pickle.dump(refer_features, pk_file)"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}