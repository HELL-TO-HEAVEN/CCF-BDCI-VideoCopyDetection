{"cells":[{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"## 相似视频检索\n\n这一步只能计算得到关键帧相似结果，但具体的视频时间段还需要进一步对齐（TODO）。"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"import glob\nimport pandas as pd\nimport pickle\n\nimport cv2\nimport imagehash\nimport numpy as np\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom scipy.spatial.distance import cosine\n\nPATH = '/home/wx/work/video_copy_detection/'\nTRAIN_PATH = PATH + 'train/'\nTEST_PATH = PATH + 'test/'\nTRAIN_QUERY_PATH = TRAIN_PATH + 'query/'\nREFER_PATH = TRAIN_PATH + 'refer/'\nTRAIN_QUERY_FRAME_PATH = TRAIN_PATH + 'query_frame/'\nREFER_FRAME_PATH = TRAIN_PATH + 'refer_frame/'\nTEST_QUERY_PATH = TEST_PATH + 'query/'\nTEST_QUERY_FRAME_PATH = TEST_PATH + 'query_frame/'\nCODE_DIR = PATH + 'code/'"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"# 读取特征文件\nwith open(PATH + 'var/train_query_features.pk', 'rb') as pk_file:\n    train_query_features = pickle.load(pk_file)\n\nwith open(PATH + 'var/test_query_features.pk', 'rb') as pk_file:\n    test_query_features = pickle.load(pk_file)\n\nwith open(PATH + 'var/refer_features.pk', 'rb') as pk_file:\n    refer_features = pickle.load(pk_file)"},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":"# 读取 train_query 视频的关键帧，并按照视频和关键帧时间进行排序\ntrain_query_imgs_path = []\ntrain_query_vids = []\nfor id in pd.read_csv(TRAIN_PATH + 'train.csv')['query_id']:\n    train_query_imgs_path += glob.glob(TRAIN_QUERY_FRAME_PATH + id + '/*.jpg')\n    train_query_vids += [id]\n\ntrain_query_imgs_path.sort(key = lambda x: x.lower())\ntrain_query_vids.sort(key = lambda x: x.lower())"},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":"# 读取 test_query 视频的关键帧，并按照视频和关键帧时间进行排序\ntest_query_imgs_path = []\ntest_query_vids = []\nfor id in pd.read_csv(TEST_PATH + 'submit_example.csv')['query_id']:\n    test_query_imgs_path += glob.glob(TEST_QUERY_FRAME_PATH + id + '/*.jpg')\n    test_query_vids += [id]\n\ntest_query_imgs_path.sort(key = lambda x: x.lower())\ntest_query_vids.sort(key = lambda x: x.lower())"},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":"# 读取refer视频的关键帧，并按照视频和关键帧时间进行排序\n\nrefer_imgs_path = glob.glob(REFER_FRAME_PATH + '*/*.jpg')\nrefer_imgs_path.sort(key = lambda x: x.lower())\n\nrefer_vids = []\nfor path in refer_imgs_path:\n    vid = path.split('/')[-2]\n    refer_vids += [vid]\nrefer_vids = list(set(refer_vids))\nrefer_vids.sort(key = lambda x: x.lower())"},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":"vids = np.concatenate((train_query_vids, test_query_vids, refer_vids), axis=0)"},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"125100it [00:01, 78396.50it/s]\n62555it [00:00, 103001.46it/s]\n181052it [00:19, 9323.81it/s]\n"}],"source":"# 特征按视频归类\n\nvid2features = {}\nfor (path, cur_feat) in tqdm(zip(train_query_imgs_path, train_query_features)):\n    vid = path.split('/')[-2]\n    if(not vid in vid2features):\n        vid2features[vid] = [cur_feat]\n    else:\n        vid2features[vid] = np.concatenate((vid2features[vid], [cur_feat]), axis=0)\n\nfor (path, cur_feat) in tqdm(zip(test_query_imgs_path, test_query_features)):\n    vid = path.split('/')[-2]\n    if(not vid in vid2features):\n        vid2features[vid] = [cur_feat]\n    else:\n        vid2features[vid] = np.concatenate((vid2features[vid], [cur_feat]), axis=0)\n\nfor (path, cur_feat) in tqdm(zip(refer_imgs_path, refer_features)):\n    vid = path.split('/')[-2]\n    if(not vid in vid2features):\n        vid2features[vid] = [cur_feat]\n    else:\n        vid2features[vid] = np.concatenate((vid2features[vid], [cur_feat]), axis=0)\n"},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":"#with open(PATH + 'var/vid2features.pk', 'wb') as pk_file:\n#    pickle.dump(vid2features, pk_file)"},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"data":{"text/plain":"(179, 512)"},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":"vid2features[refer_vids[0]].shape"},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"100%|██████████| 4705/4705 [00:00<00:00, 8716.62it/s]\n"}],"source":"# 计算全局特征向量\nvid2gv = {}\nfor vid in tqdm(vids):\n    cur_feat = vid2features[vid]\n    mean_feat = np.mean(cur_feat, axis=0, dtype=float)\n    vid2gv[vid] = mean_feat"},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"data":{"text/plain":"(512,)"},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":"vid2gv[vids[0]].shape"},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":"#with open(PATH + 'var/vid2gv.pk', 'wb') as pk_file:\n#    pickle.dump(vid2gv, pk_file)"},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":"def calculate_similarities(query_features, all_features):\n    \"\"\"\n      用于计算两组特征(已经做过l2-norm)之间的相似度\n      Args:\n        queries: shape: [N, D]\n        features: shape: [M, D]\n      Returns:\n        similarities: shape: [N, M]\n    \"\"\"\n    similarities = []\n    # 计算待查询视频和所有视频的距离\n    dist = np.nan_to_num(cdist(query_features, all_features, metric='cosine'))\n    for i, v in enumerate(query_features):\n        # 归一化，将距离转化成相似度\n        sim = np.round(1 - dist[i] / dist[i].max(), decimals=6)\n        # sim = 1 - dist[i]\n        # 按照相似度的从大到小排列，输出index\n        similarities += [[(s, sim[s]) for s in sim.argsort()[::-1] if not np.isnan(sim[s])]]\n    return similarities"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"path_flag = [0]\nthreshold = 0.9\nfor idx, (path, feat) in enumerate(zip(train_query_imgs_path, train_query_features)):            # (125100, 512)\n    idxs, rank_dists, rank_names = compute_cosin_distance(feat, refer_features, refer_imgs_path) # (181052, 512)\n    if rank_dists[0] > threshold:\n        # if hamming_distance(refer_hash[idxs[0]], query_hash[idx]) < 5:\n        \n        if path.split('/')[-2] != path_flag[-1]:\n            print('')\n        \n        print(path.split('/')[-1], rank_names[0].split('/')[-1])\n        path_flag.append(path.split('/')[-2])"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"Image.open(TEST_QUERY_FRAME_PATH + '016cf7e8-b8d6-11e9-930e-fa163ee49799/016cf7e8-b8d6-11e9-930e-fa163ee49799_00000031.500000.jpg')"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"Image.open(REFER_FRAME_PATH + '1293733400/1293733400_00000586.520000.jpg')"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":"# 提交一个最简单的结果\n\nsubmit_df = pd.read_csv(TEST_PATH + 'submit_example.csv')\nsubmit_df.loc[submit_df['query_id'] == '016cf7e8-b8d6-11e9-930e-fa163ee49799', \n              ['query_time_range(ms)', 'refer_id', 'refer_time_range(ms)']] = ['0|80500', '1293733400', '554000|635000']\nsubmit_df.to_csv('result.csv', index = None, sep=',')"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}