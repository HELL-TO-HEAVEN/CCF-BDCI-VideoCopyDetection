{"cells":[{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"## 相似视频检索\n\n视频级相似匹配 -> 帧级匹配"},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":"import glob\nimport pandas as pd\nimport pickle\n\nimport cv2\nimport imagehash\nimport numpy as np\nimport networkx as nx\nfrom tqdm import tqdm\nfrom PIL import Image\nfrom scipy.spatial.distance import cdist\nfrom scipy.spatial.distance import cosine\nfrom networkx.algorithms.dag import dag_longest_path\n\nPATH = '/home/wx/work/video_copy_detection/'\nTRAIN_PATH = PATH + 'train/'\nTEST_PATH = PATH + 'test/'\nTRAIN_QUERY_PATH = TRAIN_PATH + 'query/'\nREFER_PATH = TRAIN_PATH + 'refer/'\nTRAIN_QUERY_FRAME_PATH = TRAIN_PATH + 'query_frame/'\nREFER_FRAME_PATH = TRAIN_PATH + 'refer_frame/'\nTEST_QUERY_PATH = TEST_PATH + 'query/'\nTEST_QUERY_FRAME_PATH = TEST_PATH + 'query_frame/'\nCODE_DIR = PATH + 'code/'"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"# 读取特征文件\nwith open(PATH + 'var/train_query_features.pk', 'rb') as pk_file:\n    train_query_features = pickle.load(pk_file)\n\nwith open(PATH + 'var/test_query_features.pk', 'rb') as pk_file:\n    test_query_features = pickle.load(pk_file)\n\nwith open(PATH + 'var/refer_features.pk', 'rb') as pk_file:\n    refer_features = pickle.load(pk_file)"},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":"# 读取 train_query 视频的关键帧\n# 按照视频和关键帧时间进行排序\n# 预处理工具 dict\ntrain_query_imgs_path = []\ntrain_query_vids = []\ntrain_query_vid2idx = {}\ntrain_query_idx2vid = {}\ntrain_query_vid2baseaddr = {}\ntrain_query_fid2path = {}\ntrain_query_fid2vid = {}\ntrain_query_fid2time = {}\n\nfor id in pd.read_csv(TRAIN_PATH + 'train.csv')['query_id']:\n    train_query_imgs_path += glob.glob(TRAIN_QUERY_FRAME_PATH + id + '/*.jpg')\n    train_query_vids += [id]\n\ntrain_query_imgs_path.sort(key = lambda x: x.lower())\ntrain_query_vids.sort(key = lambda x: x.lower())\n\n\nidx = 0\nfor vid in train_query_vids:\n    train_query_vid2idx[vid] = idx\n    train_query_idx2vid[idx] = vid\n    idx += 1\nfid = 0\npre_vid = \"\"\ncur_base = 0\nfor idx, path in enumerate(train_query_imgs_path):\n    cur_vid = path.split('/')[-1][:-20]\n    train_query_fid2vid[fid] = cur_vid\n    train_query_fid2path[fid] = path\n    train_query_fid2time[fid] = float(path.split('/')[-1].split('_')[-1][:-4])\n    if pre_vid != cur_vid:\n        cur_base = idx\n        pre_vid = cur_vid\n    train_query_vid2baseaddr[cur_vid] = cur_base\n    fid += 1"},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":"# path.split('/')[-1][:-20]\n# float(path.split('/')[-1].split('_')[-1][:-4])\n"},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":"# 读取 test_query 视频的关键帧\n# 按照视频和关键帧时间进行排序\n# 预处理工具 dict\ntest_query_imgs_path = []\ntest_query_vids = []\ntest_query_vid2idx = {}\ntest_query_idx2vid = {}\ntest_query_vid2baseaddr = {}\ntest_query_fid2path = {}\ntest_query_fid2vid = {}\ntest_query_fid2time = {}\n\nfor id in pd.read_csv(TEST_PATH + 'submit_example.csv')['query_id']:\n    test_query_imgs_path += glob.glob(TEST_QUERY_FRAME_PATH + id + '/*.jpg')\n    test_query_vids += [id]\n\ntest_query_imgs_path.sort(key = lambda x: x.lower())\ntest_query_vids.sort(key = lambda x: x.lower())\n\nidx = 0\nfor vid in test_query_vids:\n    test_query_vid2idx[vid] = idx\n    test_query_idx2vid[idx] = vid\n    idx += 1\nfid = 0\npre_vid = \"\"\ncur_base = 0\nfor idx, path in enumerate(test_query_imgs_path):\n    cur_vid = path.split('/')[-1][:-20]\n    test_query_fid2vid[fid] = cur_vid\n    test_query_fid2path[fid] = path\n    test_query_fid2time[fid] = float(path.split('/')[-1].split('_')[-1][:-4])\n    if pre_vid != cur_vid:\n        cur_base = idx\n        pre_vid = cur_vid\n    test_query_vid2baseaddr[cur_vid] = cur_base\n    fid += 1"},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":"# 读取 refer_query 视频的关键帧\n# 按照视频和关键帧时间进行排序\n# 预处理工具 dict\n\nrefer_imgs_path = glob.glob(REFER_FRAME_PATH + '*/*.jpg')\nrefer_imgs_path.sort(key = lambda x: x.lower())\n\nrefer_vids = []\nrefer_vid2idx = {}\nrefer_idx2vid = {}\nrefer_vid2baseaddr = {}\nrefer_fid2path = {}\nrefer_fid2vid = {}\nrefer_fid2time = {}\n\nfor path in refer_imgs_path:\n    vid = path.split('/')[-2]\n    refer_vids += [vid]\n\nrefer_vids = list(set(refer_vids))\nrefer_vids.sort(key = lambda x: x.lower())\n\nidx = 0\nfor vid in refer_vids:\n    refer_vid2idx[vid] = idx\n    refer_idx2vid[idx] = vid\n    idx += 1\nfid = 0\npre_vid = \"\"\ncur_base = 0\nfor idx, path in enumerate(refer_imgs_path):\n    cur_vid = path.split('/')[-1][:-20]\n    refer_fid2vid[fid] = cur_vid\n    refer_fid2path[fid] = path\n    refer_fid2time[fid] = float(path.split('/')[-1].split('_')[-1][:-4])\n    if pre_vid != cur_vid:\n        cur_base = idx\n        pre_vid = cur_vid\n    refer_vid2baseaddr[cur_vid] = cur_base\n    fid += 1"},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":"vids = np.concatenate((train_query_vids, test_query_vids, refer_vids), axis=0)"},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":"# 特征按视频归类\nif False:\n    vid2features = {}\n    for (path, cur_feat) in tqdm(zip(train_query_imgs_path, train_query_features)):\n        vid = path.split('/')[-2]\n        if(not vid in vid2features):\n            vid2features[vid] = [cur_feat]\n        else:\n            vid2features[vid] = np.concatenate((vid2features[vid], [cur_feat]), axis=0)\n\n    for (path, cur_feat) in tqdm(zip(test_query_imgs_path, test_query_features)):\n        vid = path.split('/')[-2]\n        if(not vid in vid2features):\n            vid2features[vid] = [cur_feat]\n        else:\n            vid2features[vid] = np.concatenate((vid2features[vid], [cur_feat]), axis=0)\n\n    for (path, cur_feat) in tqdm(zip(refer_imgs_path, refer_features)):\n        vid = path.split('/')[-2]\n        if(not vid in vid2features):\n            vid2features[vid] = [cur_feat]\n        else:\n            vid2features[vid] = np.concatenate((vid2features[vid], [cur_feat]), axis=0)\n    \n    with open(PATH + 'var/vid2features.pk', 'wb') as pk_file:\n        pickle.dump(vid2features, pk_file)\nelse:\n    with open(PATH + 'var/vid2features.pk', 'rb') as pk_file:\n        vid2features = pickle.load(pk_file)\n"},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":"(179, 1024)"},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":"vid2features[refer_vids[0]].shape"},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":"def compute_similarities(query_features, refer_features):\n    \"\"\"\n      用于计算两组特征(已经做过l2-norm)之间的相似度\n      Args:\n        query_features: shape: [1, D]\n        refer_features: shape: [M, D]\n      Returns:\n        sorted_sims: shape: [N, M]\n        unsorted_sims: shape: [N, M]\n    \"\"\"\n    sorted_sims = []\n    unsorted_sims = []\n    # 计算待查询视频和所有视频的距离\n    dist = np.nan_to_num(cdist(query_features, refer_features, metric='cosine'))\n    for i, v in enumerate(query_features):\n        # 归一化，将距离转化成相似度\n        # sim = np.round(1 - dist[i] / dist[i].max(), decimals=6)\n        sim = 1 - dist[i]\n        # 按照相似度的从大到小排列，输出index\n        unsorted_sims += [sim]\n        sorted_sims += [[(s, sim[s]) for s in sim.argsort()[::-1] if not np.isnan(sim[s])]]\n    return sorted_sims, unsorted_sims"},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[],"source":"def get_frame_alignment(query_features, refer_features, top_K=5, min_sim=0.7, max_step=5):\n    \"\"\"\n      用于计算两组特征(已经做过l2-norm)之间的帧匹配结果\n      Args:\n        query_features: shape: [N, D]\n        refer_features: shape: [M, D]\n        top_K: 取前K个refer_frame\n        min_sim: 要求query_frame与refer_frame的最小相似度\n        max_step: 有边相连的结点间的最大步长\n      Returns:\n        path_query: shape: [1, L]\n        path_refer: shape: [1, L]\n    \"\"\"\n    node_pair2id = {}\n    node_id2pair = {}\n    node_id2pair[0] = (-1, -1) # source\n    node_pair2id[(-1, -1)] = 0\n    node_num = 1\n\n    DG = nx.DiGraph()\n    DG.add_node(0)\n\n    sorted_sims, unsorted_sims = compute_similarities(query_features, refer_features)\n\n    # add nodes\n    for qf_idx in range(query_features.shape[0]):\n        for k in range(top_K):\n            rf_idx = sorted_sims[qf_idx][k][0]\n            sim = sorted_sims[qf_idx][k][1]\n            if sim < min_sim:\n                break\n            node_id2pair[node_num] = (qf_idx, rf_idx)\n            node_pair2id[(qf_idx, rf_idx)] = node_num\n            DG.add_node(node_num)\n            node_num += 1\n    \n    node_id2pair[node_num] = (query_features.shape[0], refer_features.shape[0]) # sink\n    node_pair2id[(query_features.shape[0], refer_features.shape[0])] = node_num\n    DG.add_node(node_num)\n    node_num += 1\n\n    # link nodes\n\n    for i in range(0, node_num - 1):\n        for j in range(i + 1, node_num - 1):\n            \n            pair_i = node_id2pair[i]\n            pair_j = node_id2pair[j]\n\n            if(pair_j[0] > pair_i[0] and pair_j[1] > pair_i[1] and\n               pair_j[0] - pair_i[0] <= max_step and pair_j[1] - pair_i[1] <= max_step):\n               qf_idx = pair_j[0]\n               rf_idx = pair_j[1]\n               DG.add_edge(i, j, weight=unsorted_sims[qf_idx][rf_idx])\n\n    for i in range(0, node_num - 1):\n        j = node_num - 1\n\n        pair_i = node_id2pair[i]\n        pair_j = node_id2pair[j]\n\n        if(pair_j[0] > pair_i[0] and pair_j[1] > pair_i[1] and\n            pair_j[0] - pair_i[0] <= max_step and pair_j[1] - pair_i[1] <= max_step):\n            qf_idx = pair_j[0]\n            rf_idx = pair_j[1]\n            DG.add_edge(i, j, weight=0)\n\n    longest_path = dag_longest_path(DG)\n    path_query = [node_id2pair[node_id][0] for node_id in longest_path]\n    path_refer = [node_id2pair[node_id][1] for node_id in longest_path]\n\n    return path_query, path_refer"},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"query_time_range(ms): 90400|174000\nrefer_time_range(ms): 3555120|3648280\n                                  query_id query_time_range(ms)    refer_id  \\\n2021  001c2348-b8e3-11e9-bf24-fa163ee49799         89530|173990  1226686400   \n\n     refer_time_range(ms)  \n2021      3554350|3638810  \n"}],"source":"q_vid = train_query_vids[0]\nr_vid = '1226686400'\nquery = vid2features[q_vid]\nrefer = vid2features[r_vid]\nq_baseaddr = train_query_vid2baseaddr[q_vid]\nr_baseaddr = refer_vid2baseaddr[r_vid]\npath_query, path_refer = get_frame_alignment(query, refer) # local address\ntime_query = [int(train_query_fid2time[q_baseaddr + qf_id] * 1000) for qf_id in path_query]\ntime_refer = [int(refer_fid2time[r_baseaddr + rf_id] * 1000) for rf_id in path_refer]\nprint(\"query_time_range(ms): {}|{}\".format(time_query[0], time_query[-1]))\nprint(\"refer_time_range(ms): {}|{}\".format(time_refer[0], time_refer[-1]))\n\ntrain_df = pd.read_csv(TRAIN_PATH + 'train.csv')\nprint(train_df.loc[train_df['query_id'] == q_vid])\n"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":"# 提交一个最简单的结果\n\n#submit_df = pd.read_csv(TEST_PATH + 'submit_example.csv')\n#submit_df.loc[submit_df['query_id'] == '016cf7e8-b8d6-11e9-930e-fa163ee49799', \n#              ['query_time_range(ms)', 'refer_id', 'refer_time_range(ms)']] = ['0|80500', '1293733400', '554000|635000']\n#submit_df.to_csv('result.csv', index = None, sep=',')"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}